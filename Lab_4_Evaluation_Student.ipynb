{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpA6lL5spzn-"
   },
   "source": [
    "<center><img src='https://drive.google.com/uc?export=view&id=1qJ8NqAZolTBQY7lN-deZ8xEsU3dlUiLz' width=200></center>\n",
    "\n",
    "\n",
    "<h6><center></center></h6>\n",
    "\n",
    "<h1>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "<center>Recherche d'Information et traitement de données massives </center>\n",
    "    <center> Lab 4 : Evaluation des systèmes de recherche d'information </center>\n",
    "<hr style=\" border:none; height:3px;\">\n",
    "</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvuJkzB4pzoB"
   },
   "source": [
    "\n",
    "L'objectif de cette séance est de mettre en oeuvre les différentes approches vues en cours pour évaluer les systèmes de recherche d'information.  La première partie du Lab consistera à évaluer et comparer les différents modèles mis en oeuvre dans le LAB 2 et le LAB 3, avec différents paramètres, sur la collection TIME. La deuxième partie, quant à elle, correspond à des exercices d'application disponibles sur EDUNAO (**à faire en dehors de la séance du LAB**).\n",
    " \n",
    "\n",
    "## AVANT-PROPOS\n",
    "\n",
    "Ce Lab clôture le travail pratique de la première partie du cours concernant **les fondements de la Recherche AD Hoc d'information** ainsi que leur application. Plus particulièrement, leur application s'est faite au travers de la création de moteurs de recherche sur la collection `TIME` et aujourd'hui nous clôturerons leur application par leur evaluation, toujours sur la collection `TIME`. Récapitulons les notions vues et que nous allons voir :\n",
    "+ **Lab 1** : Notions clés de l'étape d'indexation : pré-traitements linguistique sur la collection (**Segmentation, Filtrage, Normalisation**), extraction du **vocabulaire d'indexation** et construction de l'**index inversé**.\n",
    "+ **Lab 2** : Les premiers modèles de recherche de base en RI : **modèle booléen**, **modèle vectoriel** ;\n",
    "+ **Lab 3**: les **modèles de recherche  probabilistes** et, \n",
    "+ **Lab 4** : l'**Evaluation** des systèmes de RI.\n",
    "\n",
    "Ces différents Labs sont donc fortement dépendants. Pour faciliter votre travail, le répertoire concernant le LAB 4 comprend :\n",
    "+ ce fichier qui est donc l'énoncé du LAB.\n",
    "+ un répertoire [Data](./Data) qui contient le répertoire [Time](./Data/TIME) avec l'ensemble des fichiers de la collection.\n",
    "+ un répertoire [Index](./Index) qui contient différents index inversés de la collection `TIME` et plus particulièrement :\n",
    "    + le fichier [index_document](./Index/index_document) qui correspond à l'index de documents de la collection TIME écrit suivant le format décrit dans le LAB 1 et construit avec :\n",
    "        + une segmentation à l'aide du `RegExpTokenizer` de la bibliothèque `nltk` ;\n",
    "        + un filtrage à l'aide de la liste des stop-words fournis dans la collection `TIME` ;\n",
    "        + une étape de normalisation par lemmatisation à l'aide du lemmatiseur `WordNetLemmatizer` de la bibliothèque `nltk` ;\n",
    "        \n",
    "    + le fichier [index_document.pickle](./Index/index_document.pickle) qui correspond au même index de documents que le précédent mais sauvegardé avec le module [`pickle`](https://www.datacamp.com/community/tutorials/pickle-python-tutorial) de python ;\n",
    "    + le fichier [index_frequence.pickle](./Index/index_frequence.pickle) qui correspond à l'index de fréquence de la collection TIME (avec la même chaîne de traitement que précédemment) ;\n",
    "    + le fichier [index_position.pickle](./Index/index_position.pickle) qui correspond à l'index de position de la collection TIME (avec la même chaîne de traitement que précédemment à l'exception de l'étape de segmentation qui a été faite avec le tokenizer `word_tokenize` de `nltk` pour respecter l'ordre d'apparition des tokens dans les documents ;\n",
    "+ un répertoire [Utils](./Utils) qui contient les fichiers [Lab1.py](./Utils/Lab1.py) et [Lab2.py](./Utils/Lab2.py) qui contiennent l'ensemble des fonctions utiles des Lab 1 et Lab 2 et pouvant vous servir pour le Lab 4 d'aujourd'hui.\n",
    "+ une archive nommée Archive_Lab4.zip permettant l'importation des fonctions fournies et du répertoire Utils pour le cas où vous effectuez votre lab sur colab.\n",
    "    \n",
    "**IL EST DONC IMPORTANT POUR LA SUITE DE BIEN STRUCTURER VOTRE PROJET ET DE BIEN RESPECTER CETTE STRUCTURE. IL FAUDRA DONC BIEN TRAVAILLER DANS UN REPERTOIRE DANS LEQUEL VOUS AUREZ VOTRE FICHIER `.py` (editeur python) OU `.ipynb`(notebook) ET LES REPERTOIRES `DATA`, `INDEX` ET `UTILS` AINSI QUE LES FICHIERS ASSOCIÉS.**\n",
    "\n",
    "Enfin, voici à nouveau les **instructions pour permettre l'importation des fonctions fournies et du répertoire Utils pour le cas du lab effectué sur colab :**\n",
    "\n",
    "1.    Dans le dossier Lab4_Evaluation téléchargé depuis git, vous trouverez une archive Archive_Lab4.zip.\n",
    "2.   Ouvrir le panneau Fichiers de colab (c'est à dire cliquez sur le logo en forme de dossier à gauche) et cliquez sur le premier bouton en haut à gauche vous permettant de télécharger. Téléchargez ainsi l'Archive_Lab4.zip dans votre colab. Si besoin actualiser jusqu'à voir l'archive apparaître dans le panneau. \n",
    "3.    Exécutez les deux céllules de code suivantes pour déziper l'archive et installer à nouveau les librairies `nltk` et [`tt`](http://tt.brianwel.ch/en/latest/index.html). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rks_O04oMqj-"
   },
   "outputs": [],
   "source": [
    "!unzip Archive_lab4.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qUHmsKRMsrc"
   },
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AU317doDTNB0"
   },
   "outputs": [],
   "source": [
    "!pip install ttable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMfKSmd2pzoV"
   },
   "source": [
    "## PARTIE 1 : Collection TIME\n",
    "\n",
    "Dans cette partie, nous allons comparer les différents modèles de recherche sur la collection TIME. Nous avons en effet dans la collection un ensemble de requêtes et de jugements de pertinence exhaustifs sur ces requêtes au travers des fichiers fournis. En particulier :\n",
    "+ Le fichier [TIME.QUE](./Data/Time/TIME.QUE) qui contient un ensemble de requêtes exprimées en langage naturel. Chaque requête est identifiée dans le fichier par la chaîne de caractères ` *FIND      ID`\n",
    "+ Le fichier [TIME.REL](./Data/Time/TIME.REL) qui contient les jugements de pertinence exaustifs pour chaque requête. Par exemple la ligne `1  268 288 304 308 323 326 334` doit être interprétée de la manière suivante : les documents pertinents de la collection pour la requête `1` sont les documents `268 288 304 308 323 32` et `334`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Om2rr0XpzoW"
   },
   "source": [
    "### Les différents modèles\n",
    "\n",
    "Nous allons comparer les modèles ci-dessous :\n",
    "+ Le modèle booléen.\n",
    "+ Le modèle vectoriel avec différents schémas de pondération :\n",
    "    + La pondération `tf`.\n",
    "    + La pondération `tf-idf`.\n",
    "    + La pondération `tf-idf` normalisée.\n",
    "    + La pondération `tf-idf` logarithmique.\n",
    "    + La pondération `tf-idf` logarithmique normalisée.\n",
    "+ Le modèle probabiliste BIM.\n",
    "+ Le modèle probabiliste OKAPI BM 25.\n",
    "\n",
    "Votre premier travail consiste donc, sur la base des travaux faits dans les LAB 1 et LAB 2, ou des corrections fournies, d'écrire les fonctions permettant d'appliquer ces différents modèles aux requêtes du fichier [TIME.QUE](./Data/Time/TIME.QUE).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNS-O-E5pzoX"
   },
   "source": [
    "#### Première étape : récupération des index inversés.\n",
    "\n",
    "Dans cette première étape, nous allons récupérer, en les chargeant, les index inversés résultant de l'indexation de la collection `TIME` faite dans le [LAB 1](../Lab1_InvertedIndex/Lab1_Indexation-Student-Correction.ipynb). \n",
    "\n",
    "**A. Chargement de l'index de documents**\n",
    "\n",
    "Vous pouvez pour cela utiliser la fonction `load_inverted_index_pickle(filename)` du fichier `Lab1.py` comme fait dans le code ci-dessous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-jEdhkSupzoZ"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab1 import load_inverted_index_pickle\n",
    "\n",
    "# Recupération de l'index de documents\n",
    "index_document = load_inverted_index_pickle(\"./Index/index_document.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9GUlAOXnpzod"
   },
   "source": [
    "**B. Chargement de l'index de fréquence**\n",
    "\n",
    "1- Charger l'index de fréquence. Pour faciliter la suite des traitements cet index sera référencé par une variable nommée `index_frequence`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FD9uQ4p5pzof"
   },
   "outputs": [],
   "source": [
    "index_frequence = # A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rV451E1Qpzoj"
   },
   "source": [
    "**C. Chargement de l'index de position**\n",
    "\n",
    "2- Charger l'index de position. Pour faciliter la suite des traitements cet index sera référencé par une variable nommée `index_position`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kYrEdBpnpzok"
   },
   "outputs": [],
   "source": [
    "index_position = # A completer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_LA5FkRpzon"
   },
   "source": [
    "#### Deuxième  étape : récupération des requêtes.\n",
    "\n",
    "Votre premier travail consiste à charger le fichier [TIME.QUE](./Data/Time/TIME.QUE) et à parser ce fichier pour récupérer l'ensemble des requêtes que nous utiliserons pour l'évaluation. Comme pour la représentation de la Collection faite dans le LAB 1, on representera cet ensemble de requêtes sous la forme d'un dictionnaire qui a pour clé l'identifiant de la requête (l'`ID` dans la chaîne ` *FIND      ID`) et comme valeur la chaîne de caractères correspondant à la requête en langage naturel.\n",
    "\n",
    "3- Ecrire la fonction `load_requests()` permettant de récupérer les requêtes. Pour cette étape, il vous est fortement conseillé d'utiliser la même approche que celle développée pour la récupération de la collection dans le Lab 1 et l'utilisation d'expressions régulières.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pr5cJTuKpzoo"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def load_requests(filename):\n",
    "    requests = {}\n",
    "    # A completer\n",
    "    return requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RiJz6yvapzor"
   },
   "source": [
    "4- Appliquer cette fonction au fichier [TIME.QUE](./Data/Time/TIME.QUE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IwzQ-tdzpzos"
   },
   "outputs": [],
   "source": [
    "requests =# A completer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WBdohm8AQTb"
   },
   "source": [
    "Voici une capture d'écran d'un morceau du résultat :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/requests.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQo-uHTWpzov"
   },
   "source": [
    "5- Appliquer à chaque requête la même chaîne de traitements linguistiques que ceux appliqués à la collection (segmentation, filtrage et normalisation). Pensez à utiliser les fonctions du Lab 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lcld-ltxpzow"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab1 import tokenize_Regexp_corpus,remove_stop_words,load_stop_word,collection_lemmatize\n",
    "\n",
    "tokenized_requests= # A compléter\n",
    "filtered_requests=# A compléter\n",
    "lemmatized_requests=# A compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjvpytcPpzoz"
   },
   "source": [
    "#### Troisième  étape : récupération des jugements de pertinence.\n",
    "\n",
    "6- Vous allez maintenant récupérer les jugements de pertinence associés à chaque requête en parsant le fichier [TIME.REL](./Data/Time/TIME.REL). Ces jugements de pertinence seront eux aussi stockés sous la forme d'un dictionnaire avec comme **clé** l'`ID`de la requête et comme **valeur** une liste des documents jugés pertinents pour cette requête. Par exemple, la ligne `1  268 288 304 308 323 326 334` du fichier devra donc être représentée comme ceci dans le dictionnaire `{'1': ['268','288', '304', '308', '323', '326', '334' ],...}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3fAo44upzo0"
   },
   "outputs": [],
   "source": [
    "def load_relevance_judgments(filename):\n",
    "    relevance_judgments = {}\n",
    "    # A completer\n",
    "    return relevance_judgments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W53DamrXpzo4"
   },
   "source": [
    "7- Chargez et récupérez les jugements de pertinence de la collection TIME."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBXuXQu-pzo4"
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "relevance_judgments = #a compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-_vIDeIAQTl"
   },
   "source": [
    "Voici une capture d'écran d'un morceau du résultat :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/jugement.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X7v5DeyCpzo7"
   },
   "source": [
    "### EVALUATION DE RÉSULTATS DE RECHERCHE NON ORDONNÉS\n",
    "### MODÈLE BOOLÉEN\n",
    "\n",
    "Le modèle booléen est un modèle qui retourne des résultats de recherche non ordonnés. Les métriques que nous pouvons utiliser pour évaluer le système sont donc **le rappel**, **la précision** ou encore la **F-mesure** comme vues en cours et que nous pouvons calculer pour chaque requête ou moyenner sur l'ensemble des requêtes. Le principe pour évaluer le modèle est donc celui expliqué en cours (Cours 4 : évaluation - slide 28).\n",
    "\n",
    "Pour chaque requête :\n",
    "+ Exécuter le modèle sur la collection et récupérer les documents renvoyés par le système.\n",
    "+ Marquer les documents pertinents en comparant avec les jugements de pertinence.\n",
    "+ Calculer le rappel et la précision.\n",
    "\n",
    "On sauvegardera les résultats de l'évaluation sous la forme d'un dictionnaire avec comme clé l'`ID` de la requête et comme valeur un dictionnaire avec une clé par type de mesure et en valeur le résultat de la mesure calculé sur les résultats de la requête. On calculera en particulier pour chaque requête :\n",
    "+ son rappel (clé \"recall\")\n",
    "+ sa précision (clé \"precision\")\n",
    "+ la mesure F_1 (moyenne harmonique simple, c.f. slide 29 du cours 4)\n",
    "+ la mesure F avec un paramètre $\\beta$ de votre choix (c.f. slide 29 du cours 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vy5F0ffVpzo8"
   },
   "source": [
    "8- A partir des différentes fonctions du LAB 2, écrire le code permettant d'évaluer le modèle booléen sur la collection `TIME`. En particulier il sera utile de :\n",
    "\n",
    "a. Ecrire une fonction `transformation_lem_query_to_boolean(query,index,operator)` pour\n",
    "+ **Transformer la requête sous sa forme booléenne** (rappel sur les expression régulières pouvant être utile : [ici](https://python.doctor/page-expressions-regulieres-regular-python)) et la transformer **en sa notation polonaise inversée** pour pouvoir appliquer les fonctions du LAB 2. On envisagera plusieurs cas :\n",
    "    + Transformation de la requête en requête conjonctive, i.e. on considère que l'ensemble des termes de la requête sont reliés par des `AND`.\n",
    "    + Transformation de la requête en requête disjonctive, i.e. on considère que l'ensemble des termes de la requête sont reliés par des `OR`.\n",
    "+ **Vérifier que les termes de la requête sont bien des termes du vocabulaire d'index et les supprimer** ou les remplacer par leur mot le plus proche dans le vocabulaire **si ce n'est pas le cas. Ici, on se contentera de les supprimer des termes de la requête.**\n",
    "+ **Supprimer (par simplicité) les mots de type \"U.S\" de la requête** car ils ne sont pas supportés par la bibliothèque `tt` utilisée pour implémenter le modèle booléen, de même que les tokens de type nombre.\n",
    "\n",
    "b. Ecrire une fonction `apply_boolean_model(requests, collection_index,BooleanOperator)` pour appliquer le modèle booléen.\n",
    "\n",
    "c. Enfin, écrire une fonction `evaluate_boolean_model (requests, collection_index, relevance_judgments,BooleanOperator)` qui vous permettra d'évaluer le modèle booléen sur la collection `TIME`. Pour rappel, le resultat attendu en sortie est est un dictionnaire avec comme clé l'`ID` de la requête et comme valeur un dictionnaire avec une clé par type de mesure (clées : \"recall\", \"precision\", \"F_1\") et en valeur le résultat de la mesure calculé sur les résultats de la requête.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9mHXFiI7pzo9"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab2 import *\n",
    "\n",
    "\n",
    "def transformation_lem_query_to_boolean(query,index,operator):\n",
    "    boolean_query=[]\n",
    "    # A completer\n",
    "    return boolean_query\n",
    "\n",
    "def apply_boolean_model(requests, collection_index,BooleanOperator):\n",
    "    results ={}\n",
    "    # A completer\n",
    "    return results\n",
    "\n",
    "\n",
    "def evaluate_boolean_model (requests, collection_index, relevance_judgments,BooleanOperator):\n",
    "    evaluation_boolean = {}\n",
    "    # A completer\n",
    "    return evaluation_boolean\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpFfe84cAQTq"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "\n",
    "BooleanOperator = {'AND', 'NOT', 'OR'}\n",
    "a = evaluate_boolean_model(lemmatized_requests, index_document, relevance_judgments,BooleanOperator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tz_DlcVAQTs"
   },
   "source": [
    "Voici une capture d'écran d'un morceau du résultat (en considérant le cas d'une requête disjonctive) :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/boolean.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "709FP92Qpzo_"
   },
   "source": [
    "### EVALUATION DE RÉSULTATS ORDONNÉS\n",
    "\n",
    "\n",
    "#### Courbe Rappel-Précision\n",
    "\n",
    "\n",
    "Pour les modèles qui permettent d'ordonner les résultats, nous allons d'abord les comparer à l'aide des courbes rappel-precision.\n",
    "\n",
    "\n",
    "Avant de vous lancer dans cette étape, prenez le temps de relire les slides 31 à 35 du cours 4.\n",
    "\n",
    "9- Ecrire la fonction `run_model_and_evaluate(query, query_id ,inverted_index, stats, model, relevance_judgments)` qui applique le modèle `model` à la requête et qui calcule les informations des 3 premières colonnes dans le tableau rappelé ci-dessous (cf. slide 33).\n",
    "\n",
    "\n",
    "<img src=\"./Figures/recalprecisioncurve.png\" width=\"500\" height=\"500\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bopdcDCxpzpB"
   },
   "outputs": [],
   "source": [
    "from Utils.Lab2 import *\n",
    "\n",
    "collection_TIME = loadData(\"./Data/Time/TIME.ALL\")\n",
    "pre_processed_collection_TIME = collection_lemmatize(remove_stop_words(tokenize_Regexp_corpus(collection_TIME),\"./Data/Time/TIME.STP\"))\n",
    "stats=get_stats_collection(pre_processed_collection_TIME)\n",
    "\n",
    "\n",
    "\n",
    "def run_model_and_evaluate(query, query_id ,inverted_index, stats, model, relevance_judgments):\n",
    "    # A completer \n",
    "     return result_with_relevance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ia32vXiLAQTy"
   },
   "outputs": [],
   "source": [
    "#Test\n",
    "query = requests[\"1\"] # requests correspond à l'ensemble des requête récupérer à la \"Deuxième étape : récupération des requêtes.\"\n",
    "print(query)\n",
    "\n",
    "run_model_and_evaluate(query, \"1\", index_frequence,stats, ['frequency','binary'],relevance_judgments)\n",
    "\n",
    "# frequency: weighting_scheme_document (voir Lab2, modèle vectoriel)\n",
    "# binary: weighting_scheme_query (voir Lab2, modèle vectoriel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sIGodaHlTNCC"
   },
   "source": [
    "Voici une capture d'écran d'un morceau du résultat :\n",
    "\n",
    "\n",
    "<img src=\"./Figures/test-evaluate-order.png\" width=\"600\" height=\"600\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "epUwvevhxXj9"
   },
   "source": [
    "\n",
    "## PARTIE 2 : EXERCICES \n",
    "\n",
    "Une série d'exercices est disponible sur EDUNAO et est à travailler en **dehors de la séance**. Elle vous permettra de réviser pour l'examen. "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Lab_4_Evaluation_Student.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
